# video.py
import cv2
import time
from PyQt6.QtCore import QThread, pyqtSignal
from PyQt6.QtGui import QImage
from ai_engine import TrashDetector

class VideoThread(QThread):
    change_pixmap_signal = pyqtSignal(QImage)
    ai_results_signal = pyqtSignal(dict) # G·ª≠i dict ch·ª©a list detections
    fps_signal = pyqtSignal(int)
    
    def __init__(self, cam_ip, model_path):
        super().__init__()
        self.cam_ip = cam_ip
        self.running = True
        self.enable_ai = False # M·∫∑c ƒë·ªãnh t·∫Øt AI (Manual Mode)
        
        # Kh·ªüi t·∫°o AI Engine
        self.detector = TrashDetector(model_path=model_path)
        
    def run(self):
        print(f"üé• Connecting to Camera: {self.cam_ip}")
        cap = cv2.VideoCapture(self.cam_ip)
        
        # T·ªëi ∆∞u buffer ƒë·ªÉ gi·∫£m lag
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
        prev_time = 0
        while self.running:
            if not self.cam_ip: 
                time.sleep(0.1)
                continue
            try:
                ret, frame = cap.read()
                if ret:
                    # 1. T√≠nh FPS
                    now = time.time()
                    fps = 1 / (now - prev_time) if (now - prev_time) > 0 else 0
                    prev_time = now
                    self.fps_signal.emit(int(fps))
                    
                    # 2. X·ª≠ l√Ω AI (N·∫øu b·∫≠t)
                    final_frame = frame
                    detections = []
                    
                    if self.enable_ai:
                        # Resize v·ªÅ 640x480 ƒë·ªÉ AI ch·∫°y nhanh h∆°n
                        frame_resized = cv2.resize(frame, (640, 480))
                        annotated_frame, detections = self.detector.detect(frame_resized)
                        final_frame = annotated_frame
                        
                        # G·ª≠i k·∫øt qu·∫£ v·ªÅ Main
                        self.ai_results_signal.emit({'detections': detections})
                    
                    # 3. Convert sang Qt Image ƒë·ªÉ hi·ªÉn th·ªã
                    rgb_frame = cv2.cvtColor(final_frame, cv2.COLOR_BGR2RGB)
                    h, w, ch = rgb_frame.shape
                    bytes_per_line = ch * w
                    qt_img = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format.Format_RGB888)
                    
                    # Scale ·∫£nh cho v·ª´a khung nh√¨n n·∫øu c·∫ßn (nh∆∞ng gi·ªØ t·ª∑ l·ªá)
                    self.change_pixmap_signal.emit(qt_img)
                    
                else:
                    # M·∫•t k·∫øt n·ªëi, th·ª≠ l·∫°i sau 1s
                    time.sleep(1)
                    if self.running: cap.open(self.cam_ip)
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Video Error: {e}")
                time.sleep(1)
        
        cap.release()
        print("üé• Video Thread Stopped")
    
    def update_source(self, cam_ip):
        print(f"üîÑ Switching Camera to: {cam_ip}")
        self.running = False # D·ª´ng v√≤ng l·∫∑p t·∫°m th·ªùi
        self.wait()          # Ch·ªù thread d·ª´ng h·∫≥n
        
        self.cam_ip = cam_ip
        self.running = True  # B·∫≠t l·∫°i c·ªù
        self.start()
    
    def set_ai_mode(self, enabled):
        self.enable_ai = enabled

    def update_conf(self, val):
        self.detector.update_conf(val)
    
    def stop(self):
        self.running = False
        self.wait()