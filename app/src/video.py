# video.py
import cv2
import time
from PyQt6.QtCore import QThread, pyqtSignal, QMutex
from PyQt6.QtGui import QImage
from ai_engine import TrashDetector

class VideoThread(QThread):
    change_pixmap_signal = pyqtSignal(QImage)
    ai_results_signal = pyqtSignal(dict)
    fps_signal = pyqtSignal(int)
    
    def __init__(self, cam_ip, model_path):
        super().__init__()
        self.cam_ip = cam_ip
        self.running = True
        self.enable_ai = False
        self.detector = TrashDetector(model_path=model_path)
        
        # Biáº¿n Ä‘iá»u khiá»ƒn viá»‡c Ä‘á»•i IP an toÃ n
        self.pending_ip = None 
        self.mutex = QMutex()

    def run(self):
        print(f"ğŸ¥ Starting Video Thread: {self.cam_ip}")
        cap = cv2.VideoCapture()
        
        # Má»Ÿ káº¿t ná»‘i ban Ä‘áº§u
        if self.cam_ip:
            cap.open(self.cam_ip)
            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

        prev_time = 0
        
        while self.running:
            # 1. KIá»‚M TRA YÃŠU Cáº¦U Äá»”I IP (Non-blocking)
            self.mutex.lock()
            if self.pending_ip is not None:
                new_ip = self.pending_ip
                self.pending_ip = None
                self.mutex.unlock()
                
                print(f"ğŸ”„ Switching Stream to: {new_ip}")
                if cap.isOpened(): cap.release()
                
                # Thá»­ káº¿t ná»‘i IP má»›i (HÃ nh Ä‘á»™ng nÃ y tá»‘n thá»i gian nhÆ°ng náº±m trong Thread nÃªn ko Ä‘Æ¡ UI)
                cap.open(new_ip)
                cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                self.cam_ip = new_ip
            else:
                self.mutex.unlock()

            # 2. Äá»c Frame
            if not cap.isOpened():
                time.sleep(0.5) # Nghá»‰ chÃºt náº¿u chÆ°a káº¿t ná»‘i Ä‘Æ°á»£c
                continue

            try:
                ret, frame = cap.read()
                if ret:
                    # TÃ­nh FPS
                    now = time.time()
                    fps = int(1 / (now - prev_time)) if (now - prev_time) > 0 else 0
                    prev_time = now
                    self.fps_signal.emit(fps)
                    
                    # AI Processing
                    final_frame = frame
                    detections = []
                    if self.enable_ai:
                        # Resize 640x480 Ä‘á»ƒ Ä‘á»“ng bá»™ model
                        frame_resized = cv2.resize(frame, (640, 480))
                        annotated_frame, detections = self.detector.detect(frame_resized)
                        final_frame = annotated_frame
                        self.ai_results_signal.emit({'detections': detections})
                    
                    # Convert QImage
                    rgb_frame = cv2.cvtColor(final_frame, cv2.COLOR_BGR2RGB)
                    h, w, ch = rgb_frame.shape
                    bytes_per_line = ch * w
                    qt_img = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format.Format_RGB888)
                    self.change_pixmap_signal.emit(qt_img)
                else:
                    # Máº¥t káº¿t ná»‘i frame -> Thá»­ láº¡i nháº¹ nhÃ ng
                    time.sleep(0.1)
                    
            except Exception as e:
                print(f"âš ï¸ Stream Error: {e}")
                time.sleep(1)

        cap.release()
        print("ğŸ¥ Video Thread Stopped Cleanly")
    
    def update_source(self, new_ip):
        # HÃ m nÃ y Ä‘Æ°á»£c gá»i tá»« UI, chá»‰ gÃ¡n biáº¿n flag rá»“i return ngay láº­p tá»©c -> KHÃ”NG ÄÆ  UI
        self.mutex.lock()
        self.pending_ip = new_ip
        self.mutex.unlock()
    
    def set_ai_mode(self, enabled):
        self.enable_ai = enabled

    def update_conf(self, val):
        self.detector.update_conf(val)
    
    def stop(self):
        self.running = False
        self.wait() # Chá» thread káº¿t thÃºc tÃ¡c vá»¥ hiá»‡n táº¡i rá»“i Ä‘Ã³ng