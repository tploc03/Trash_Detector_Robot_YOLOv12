{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13837980,"sourceType":"datasetVersion","datasetId":8813270}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall -y ultralytics\n\n!pip install -q git+https://github.com/sunsmarterjie/yolov12.git\n!pip install -q flash-attn supervision\n\n!pip uninstall -y tensorboard tensorflow\n\nprint(\"âœ… ÄÃ£ cÃ i xong YOLOv12 vÃ  gá»¡ bá» xung Ä‘á»™t.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T12:16:04.004137Z","iopub.execute_input":"2025-11-23T12:16:04.004895Z","iopub.status.idle":"2025-11-23T12:19:00.698725Z","shell.execute_reply.started":"2025-11-23T12:16:04.004868Z","shell.execute_reply":"2025-11-23T12:19:00.697711Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping ultralytics as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for ultralytics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nnumba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\ndatasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m212.4/212.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\nFound existing installation: tensorboard 2.18.0\nUninstalling tensorboard-2.18.0:\n  Successfully uninstalled tensorboard-2.18.0\nFound existing installation: tensorflow 2.18.0\nUninstalling tensorflow-2.18.0:\n  Successfully uninstalled tensorflow-2.18.0\nâœ… ÄÃ£ cÃ i xong YOLOv12 vÃ  gá»¡ bá» xung Ä‘á»™t.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# 4. QUAN TRá»ŒNG: BÃ¢y giá» má»›i háº¡ cáº¥p numpy xuá»‘ng 1.26.4\n!pip install -q numpy==1.26.4\n\nprint(\"âœ… ÄÃ£ háº¡ cáº¥p numpy xuá»‘ng 1.26.4.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T12:19:00.700583Z","iopub.execute_input":"2025-11-23T12:19:00.700893Z","iopub.status.idle":"2025-11-23T12:19:07.139865Z","shell.execute_reply.started":"2025-11-23T12:19:00.700866Z","shell.execute_reply":"2025-11-23T12:19:07.139086Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, which is not installed.\ndatasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mâœ… ÄÃ£ háº¡ cáº¥p numpy xuá»‘ng 1.26.4.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import textwrap\n\n# --- ÄÆ¯á»œNG DáºªN ÄÃƒ CHáº®C CHáº®N ÄÃšNG ---\n# 1. TÃªn dataset báº¡n Ä‘áº·t á»Ÿ BÆ°á»›c 1\ndataset_name = 'yolo_dataset'\n# 2. TÃªn thÆ° má»¥c gá»‘c bÃªn trong file zip (thÆ° má»¥c chá»©a 'images' vÃ  'labels')\n# root_folder_in_zip = 'datasets' \n# ---\n\n# Táº¡o Ä‘Æ°á»ng dáº«n Kaggle Ä‘áº§y Ä‘á»§\nkaggle_dataset_path = f\"/kaggle/input/yolo-dataset/{dataset_name}\"\n\n# Ná»˜I DUNG YAML ÄÃƒ Sá»¬A ÄÆ¯á»œNG DáºªN TÆ¯Æ NG Äá»I\nyaml_content = f\"\"\"\npath: {kaggle_dataset_path}\ntrain: images/train\nval: images/val\ntest: images/test\n\n# ThÃ´ng tin cÃ¡c lá»›p\nnc: 7\nnames:\n  0: battery\n  1: cardboard\n  2: glass\n  3: metal\n  4: organic\n  5: paper\n  6: plastic\n\"\"\"\n\n# DÃ¹ng dedent Ä‘á»ƒ xÃ³a cÃ¡c khoáº£ng tráº¯ng thá»¥t lá»\nclean_yaml_content = textwrap.dedent(yaml_content)\n\n# ÄÆ°á»ng dáº«n Ä‘á»ƒ lÆ°u file yaml Táº M THá»œI (trong thÆ° má»¥c cÃ³ thá»ƒ ghi)\nyaml_save_path = '/kaggle/working/yolo_dataset.yaml'\n\nwith open(yaml_save_path, 'w') as f:\n    f.write(clean_yaml_content)\n\nprint(f\"ÄÃ£ táº¡o file 'trash_data.yaml' táº¡i: {yaml_save_path}\")\nprint(f\"File nÃ y trá» Ä‘áº¿n dá»¯ liá»‡u táº¡i: {kaggle_dataset_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T12:19:07.140912Z","iopub.execute_input":"2025-11-23T12:19:07.141168Z","iopub.status.idle":"2025-11-23T12:19:07.147646Z","shell.execute_reply.started":"2025-11-23T12:19:07.141141Z","shell.execute_reply":"2025-11-23T12:19:07.147077Z"}},"outputs":[{"name":"stdout","text":"ÄÃ£ táº¡o file 'trash_data.yaml' táº¡i: /kaggle/working/yolo_dataset.yaml\nFile nÃ y trá» Ä‘áº¿n dá»¯ liá»‡u táº¡i: /kaggle/input/yolo-dataset/yolo_dataset\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from ultralytics import YOLO\nimport torch\n\n# Giáº£i phÃ³ng bá»™ nhá»› (dÃ¹ restart rá»“i nhÆ°ng cá»© Ä‘á»ƒ cho cháº¯c)\ntorch.cuda.empty_cache()\n\n# 1. Táº£i mÃ´ hÃ¬nh\nmodel = YOLO('yolov12n.pt') \n\nprint(\"ğŸš€ Äang cáº¥u hÃ¬nh vÃ  báº¯t Ä‘áº§u huáº¥n luyá»‡n...\")\n\n# 2. Báº¯t Ä‘áº§u huáº¥n luyá»‡n\nresults = model.train(\n    data='/kaggle/working/yolo_dataset.yaml',\n    \n    epochs=300,\n    patience=50,\n    \n    # --- Cáº¤U HÃŒNH AN TOÃ€N CHO Bá»˜ NHá»š ---\n    batch=16,              # Giá»¯ 16 lÃ  an toÃ n cho T4\n    imgsz=640,\n    cache=False,           # <--- Äá»”I THÃ€NH FALSE Ä‘á»ƒ trÃ¡nh lá»—i trÃ n bá»™ nhá»› lÃºc load áº£nh\n    \n    # --- Xá»¬ LÃ Lá»–I AMP ---\n    amp=True,              # True lÃ  tá»‘t (tiáº¿t kiá»‡m VRAM hÆ¡n False)\n    \n    close_mosaic=10,       \n    \n    project='/kaggle/working/training_runs',\n    name='yolov12_trash_best',\n    exist_ok=True,\n    verbose=True,\n    plots=True,\n    save=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T12:19:07.149329Z","iopub.execute_input":"2025-11-23T12:19:07.149543Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file âœ… \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/yolov12/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nFlashAttention is not available on this device. Using scaled_dot_product_attention instead.\nDownloading https://github.com/sunsmarterjie/yolov12/releases/download/turbo/yolov12n.pt to 'yolov12n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.26M/5.26M [00:00<00:00, 64.7MB/s]\n","output_type":"stream"},{"name":"stdout","text":"ğŸš€ Äang cáº¥u hÃ¬nh vÃ  báº¯t Ä‘áº§u huáº¥n luyá»‡n...\nNew https://pypi.org/project/ultralytics/8.3.230 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\nUltralytics 8.3.63 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov12n.pt, data=/kaggle/working/yolo_dataset.yaml, epochs=300, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/kaggle/working/training_runs, name=yolov12_trash_best, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.1, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/kaggle/working/training_runs/yolov12_trash_best\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/yolov12/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 15.6MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=7\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      2368  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2, 1, 2]          \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1      9344  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2, 1, 4]          \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  2    174720  ultralytics.nn.modules.block.A2C2f           [128, 128, 2, True, 4]        \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  2    677120  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 1]        \n  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 11                  -1  1     86912  ultralytics.nn.modules.block.A2C2f           [384, 128, 1, False, -1]      \n 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 14                  -1  1     24000  ultralytics.nn.modules.block.A2C2f           [256, 64, 1, False, -1]       \n 15                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 17                  -1  1     74624  ultralytics.nn.modules.block.A2C2f           [192, 128, 1, False, -1]      \n 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 20                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 21        [14, 17, 20]  1    432037  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \nYOLOv12n summary: 497 layers, 2,521,029 parameters, 2,521,013 gradients, 6.0 GFLOPs\n\nTransferred 688/739 items from pretrained weights\nFreezing layer 'model.21.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/yolo-dataset/yolo_dataset/labels/train... 4458 images, 3 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4458/4458 [00:23<00:00, 191.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ Cache directory /kaggle/input/yolo-dataset/yolo_dataset/labels is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/ultralytics/data/augment.py:1853: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n  A.ImageCompression(quality_lower=75, p=0.0),\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/yolo-dataset/yolo_dataset/labels/val... 1288 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1288/1288 [00:06<00:00, 194.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ Cache directory /kaggle/input/yolo-dataset/yolo_dataset/labels is not writeable, cache not saved.\nPlotting labels to /kaggle/working/training_runs/yolov12_trash_best/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 121 weight(decay=0.0), 128 weight(decay=0.0005), 127 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/training_runs/yolov12_trash_best\u001b[0m\nStarting training for 300 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      1/300      3.71G      1.056      3.103      1.414         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:42<00:00,  2.73it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:16<00:00,  2.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909      0.491      0.463      0.469      0.328\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      2/300      3.74G      1.083      2.028      1.395         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:38<00:00,  2.84it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:14<00:00,  2.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909      0.587      0.533      0.569      0.392\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      3/300      3.75G      1.133       1.94      1.436         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:37<00:00,  2.86it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:14<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909      0.315      0.355      0.295      0.171\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      4/300       3.7G      1.211      1.997      1.519         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:36<00:00,  2.88it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:14<00:00,  2.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909      0.489       0.44       0.43      0.279\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      5/300       3.7G      1.204      1.836      1.505         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:36<00:00,  2.88it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:14<00:00,  2.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909      0.563       0.51      0.532       0.36\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      6/300      3.68G      1.185      1.713      1.486         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:36<00:00,  2.88it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:14<00:00,  2.92it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909      0.546       0.55      0.563      0.388\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      7/300       3.7G       1.14      1.592      1.454         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:36<00:00,  2.88it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:13<00:00,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909      0.564      0.591      0.589      0.419\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      8/300       3.7G      1.122       1.53      1.436         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:36<00:00,  2.88it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:14<00:00,  2.92it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909      0.619      0.542      0.572      0.394\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      9/300      3.69G        1.1      1.467      1.425         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:36<00:00,  2.88it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:13<00:00,  2.95it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909      0.588        0.6      0.618      0.456\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     10/300      3.59G      1.092      1.422      1.414         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:36<00:00,  2.88it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:13<00:00,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909      0.702      0.557      0.626       0.45\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     11/300      3.69G      1.055      1.341       1.39         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:36<00:00,  2.88it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:14<00:00,  2.93it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909      0.628       0.58      0.609      0.426\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     12/300      3.69G      1.069      1.345      1.409         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:36<00:00,  2.89it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:14<00:00,  2.91it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909      0.671      0.638      0.676      0.494\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     13/300      3.72G      1.043      1.278      1.382         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:36<00:00,  2.89it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:13<00:00,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909      0.752      0.659      0.729      0.545\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     14/300      3.59G      1.039       1.26      1.374         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:36<00:00,  2.88it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:13<00:00,  2.95it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909      0.733      0.661      0.725      0.549\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     15/300      3.71G      1.038      1.234       1.37         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:36<00:00,  2.88it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:13<00:00,  2.95it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909      0.759      0.654      0.733       0.55\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     16/300       3.6G      1.005      1.185      1.349         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:36<00:00,  2.88it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:13<00:00,  2.96it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909      0.764      0.676      0.757      0.563\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     17/300      3.69G      1.006      1.171      1.344         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:37<00:00,  2.88it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:13<00:00,  2.95it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909       0.79       0.68       0.76      0.573\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     18/300      3.59G      1.003      1.159       1.35         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:36<00:00,  2.89it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:14<00:00,  2.93it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909      0.736      0.646      0.724      0.553\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     19/300      3.72G     0.9979      1.112      1.339         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:36<00:00,  2.88it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:13<00:00,  2.95it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909       0.77       0.71      0.777      0.593\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     20/300      3.72G     0.9876      1.103       1.34         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:36<00:00,  2.88it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:14<00:00,  2.91it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1288       1909      0.787      0.668      0.769       0.58\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     21/300      3.71G     0.9944      1.074      1.335         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279/279 [01:36<00:00,  2.88it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 39/41 [00:13<00:00,  2.85it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nimport torch\n\n# Giáº£i phÃ³ng bá»™ nhá»› (dÃ¹ restart rá»“i nhÆ°ng cá»© Ä‘á»ƒ cho cháº¯c)\ntorch.cuda.empty_cache()\n\n# 1. Táº£i mÃ´ hÃ¬nh\nmodel = YOLO('yolov12n.pt') \n\nprint(\"ğŸš€ Äang cáº¥u hÃ¬nh vÃ  báº¯t Ä‘áº§u huáº¥n luyá»‡n...\")\n\n# 2. Báº¯t Ä‘áº§u huáº¥n luyá»‡n\nresults = model.train(\n    data='/kaggle/working/yolo_dataset.yaml',\n    \n    epochs=300,\n    patience=50,\n    \n    # --- Cáº¤U HÃŒNH AN TOÃ€N CHO Bá»˜ NHá»š ---\n    batch=16,              # Giá»¯ 16 lÃ  an toÃ n cho T4\n    imgsz=640,\n    cache=False,           # <--- Äá»”I THÃ€NH FALSE Ä‘á»ƒ trÃ¡nh lá»—i trÃ n bá»™ nhá»› lÃºc load áº£nh\n    \n    # --- Xá»¬ LÃ Lá»–I AMP ---\n    amp=True,              # True lÃ  tá»‘t (tiáº¿t kiá»‡m VRAM hÆ¡n False)\n    \n    close_mosaic=10,       \n    \n    project='/kaggle/working/training_runs',\n    name='yolov12_trash_best',\n    exist_ok=True,\n    verbose=True,\n    plots=True,\n    save=True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# KIá»‚M TRA Láº I Vá»šI TÃŠN ÄÃšNG\ndataset_name = \"yolo-dataset\" # <--- ÄÃƒ Sá»¬A THÃ€NH Gáº CH Ná»I\ndataset_path = f\"/kaggle/input/{dataset_name}\"\n\nif os.path.exists(dataset_path):\n    print(f\"\\nBÃŠN TRONG {dataset_path} CÃ“:\")\n    # In ra cÃ¡c thÆ° má»¥c/file cáº¥p 1\n    items = os.listdir(dataset_path)\n    print(items)\n    \n    # Kiá»ƒm tra sÃ¢u hÆ¡n náº¿u cÃ³ thÆ° má»¥c 'images', 'train', hoáº·c 'datasets'\n    for item in items:\n        sub_path = os.path.join(dataset_path, item)\n        if os.path.isdir(sub_path):\n            print(f\"  --- BÃªn trong {item}: {os.listdir(sub_path)[:5]}...\") # Chá»‰ in 5 má»¥c Ä‘áº§u\nelse:\n    print(f\"âŒ ThÆ° má»¥c {dataset_path} khÃ´ng tá»“n táº¡i.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}